{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Augment the image by flipping, ColorJitter, GaussianBlur, and change the bounding box accordingly\n",
    "'''\n",
    "\n",
    "def augment_image(image, bbox):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    \n",
    "    # Convert bbox to format required for PIL (left, upper, right, lower)\n",
    "    #(x_min, y_min, x_max, y_max) = bbox\n",
    "    bbox_pil = [bbox[0], bbox[1], bbox[2], bbox[3]]\n",
    "\n",
    "    \n",
    "    # Define the augmentation pipeline\n",
    "    flag = random.randint(0, 3)\n",
    "    if flag == 0:\n",
    "        image = np.flip(image, [0])\n",
    "        bbox_pil[1] = pil_image.size[1] - bbox_pil[1]\n",
    "        bbox_pil[3] = pil_image.size[1] - bbox_pil[3]\n",
    "    elif flag == 1:\n",
    "        image = np.flip(image, [1])\n",
    "        bbox_pil[0] = pil_image.size[0] - bbox_pil[0]\n",
    "        bbox_pil[2] = pil_image.size[0] - bbox_pil[2]\n",
    "    elif flag == 2:\n",
    "        image = np.flip(image, [0, 1])\n",
    "        bbox_pil[0] = pil_image.size[0] - bbox_pil[0]\n",
    "        bbox_pil[2] = pil_image.size[0] - bbox_pil[2]\n",
    "        bbox_pil[1] = pil_image.size[1] - bbox_pil[1]\n",
    "        bbox_pil[3] = pil_image.size[1] - bbox_pil[3]\n",
    "    else:\n",
    "        pass # same image\n",
    "    \n",
    "\n",
    "    color_jitter = transforms.ColorJitter(\n",
    "        brightness=0.2,    # Randomly change brightness\n",
    "        contrast=0.2,      # Randomly change contrast\n",
    "        saturation=0.2,    # Randomly change saturation\n",
    "        hue=0.1            # Randomly change hue\n",
    "    )\n",
    "\n",
    "    image = color_jitter(Image.fromarray(image))\n",
    "    image = np.array(image)\n",
    "\n",
    "    blur = transforms.GaussianBlur(kernel_size=(5,25), sigma=(0.1, 5))\n",
    "    image = blur(Image.fromarray(image))\n",
    "    image = np.array(image)\n",
    "\n",
    "    \n",
    "    return image, bbox_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Convert the bounding box from pixel format to normalized format\n",
    "'''\n",
    "def normalized_to_pixel_bbox(data, img_width, img_height):\n",
    "    x_min = (data[\"x\"] / 100) * img_width\n",
    "    y_min = (data[\"y\"] / 100) * img_height\n",
    "    width = (data[\"width\"] / 100) * img_width\n",
    "    height = (data[\"height\"] / 100) * img_height\n",
    "    x_max = x_min + width\n",
    "    y_max = y_min + height\n",
    "    # print(x_min, y_min, x_max, y_max)\n",
    "    return [x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Adjust the bounding box to the new image size\n",
    "'''\n",
    "def adjust_bounding_boxes(bboxes, original_size, target_size):\n",
    "    original_width, original_height = original_size\n",
    "    target_width, target_height = target_size\n",
    "    \n",
    "    scale_width = target_width / original_width\n",
    "    scale_height = target_height / original_height\n",
    "    \n",
    "    adjusted_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x_min = bbox['x_min']\n",
    "        y_min = bbox['y_min']\n",
    "        x_max = bbox['x_max']\n",
    "        y_max = bbox['y_max']\n",
    "        x_min_adj = x_min * scale_width\n",
    "        y_min_adj = y_min * scale_height\n",
    "        x_max_adj = x_max * scale_width\n",
    "        y_max_adj = y_max * scale_height\n",
    "        \n",
    "        adjusted_bboxes.append((x_min_adj, y_min_adj, x_max_adj, y_max_adj))\n",
    "    \n",
    "    return adjusted_bboxes  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Resized Training Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(num_augmentations, start_index, csv_data, image_path, target_size, has_symbol=True, resize_image=False, validation=False):\n",
    "      # Update with the actual path\n",
    "    image = cv2.imread(image_path) # The image is loaded in BGR format\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for visualization\n",
    "\n",
    "    bbox = normalized_to_pixel_bbox(csv_data, csv_data[\"original_width\"], csv_data[\"original_height\"])\n",
    "\n",
    "    # Number of augmentations to generate\n",
    "    augmented_results = []\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_image, adjusted_bbox = augment_image(image.copy(), bbox.copy())\n",
    "        augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize the augmented image and bounding box\n",
    "        if resize_image:\n",
    "            augmented_image = cv2.resize(augmented_image, target_size)\n",
    "            temp = {\n",
    "                'x_min': adjusted_bbox[0],\n",
    "                'y_min': adjusted_bbox[1],\n",
    "                'x_max': adjusted_bbox[2],\n",
    "                'y_max': adjusted_bbox[3]\n",
    "            }\n",
    "            adjusted_bbox = adjust_bounding_boxes([temp], (csv_data[\"original_width\"], csv_data[\"original_height\"]), target_size)[0]\n",
    "        # ----------------------------\n",
    "\n",
    "        augmented_image_np = np.array(augmented_image)\n",
    "        augmented_results.append((augmented_image_np, adjusted_bbox))\n",
    "\n",
    "    bbox_annotations = []\n",
    "    for i, (augmented_image, adjusted_bbox) in enumerate(augmented_results):\n",
    "        # Save augmented image\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "        augmented_image_path = f'data/image_{i+start_index}.jpg'\n",
    "        if validation:\n",
    "            if not os.path.exists('validation_data'):\n",
    "                os.makedirs('validation_data')\n",
    "            augmented_image_path = f'validation_data/image_{i+start_index}.jpg'\n",
    "        if resize_image:\n",
    "            if not os.path.exists('resized_data'):\n",
    "                os.makedirs('resized_data')\n",
    "            augmented_image_path = f'resized_data/image_{i+start_index}.jpg'\n",
    "            if validation:\n",
    "                if not os.path.exists('resized_validation_data'):\n",
    "                    os.makedirs('resized_validation_data')\n",
    "                augmented_image_path = f'resized_validation_data/image_{i+start_index}.jpg'\n",
    "\n",
    "        \n",
    "        image_name = f'image_{i+start_index}.jpg'\n",
    "        cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "        if has_symbol:\n",
    "            bbox = {\n",
    "                'x_min': adjusted_bbox[0],\n",
    "                'y_min': adjusted_bbox[1],\n",
    "                'x_max': adjusted_bbox[2],\n",
    "                'y_max': adjusted_bbox[3]\n",
    "            }\n",
    "        else:\n",
    "            bbox = {\n",
    "                'x_min': 0,\n",
    "                'y_min': 0,\n",
    "                'x_max': 0,\n",
    "                'y_max': 0\n",
    "            }\n",
    "\n",
    "        # Save adjusted bounding box coordinates to the annotations list\n",
    "        bbox_data = {\n",
    "            'image_path': image_name,\n",
    "            'has_symbol': 1 if has_symbol else 0,\n",
    "            'bbox': bbox\n",
    "        }\n",
    "        bbox_annotations.append(bbox_data)\n",
    "    return bbox_annotations\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_data = {\n",
    "    \"x\": 5.075424261470773,\n",
    "    \"y\": 10.69767441860465,\n",
    "    \"width\": 19.721648558857858,\n",
    "    \"height\": 31.395348837209305,\n",
    "    \"rotation\": 0,\n",
    "    \"rectanglelabels\": [\"CCP\"],\n",
    "    \"original_width\": 1036,\n",
    "    \"original_height\": 646 \n",
    "    }\n",
    "back_1_data = {\n",
    "    \"x\":5.0754242614707605,\n",
    "    \"y\":9.302325581395342,\n",
    "    \"width\":19.14160007183262,\n",
    "    \"height\":32.32558139534885,\n",
    "    \"rotation\": 0,\n",
    "    \"rectanglelabels\": [\"CCP\"],\n",
    "    \"original_width\": 1036,\n",
    "    \"original_height\": 646\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training(num_augmentations=100):\n",
    "    image_path = 'original_data/back.bmp'\n",
    "    target_size = (256, 256)\n",
    "    bbox_annotations = generate_image(num_augmentations, 0, back_data, image_path, target_size, has_symbol=True, resize_image=True, validation=False)\n",
    "    image_path = 'original_data/back_1.bmp'\n",
    "    bbox_annotations += generate_image(num_augmentations, num_augmentations, back_1_data, image_path, target_size, has_symbol=True, resize_image=True, validation=False)\n",
    "    image_path = 'original_data/front.bmp'\n",
    "    bbox_annotations += generate_image(num_augmentations, 2 * num_augmentations, back_data, image_path, target_size, has_symbol=False, resize_image=True, validation=False)\n",
    "    image_path = 'original_data/stain_back.bmp'\n",
    "    bbox_annotations += generate_image(num_augmentations, 3 * num_augmentations, back_data, image_path, target_size, has_symbol=False, resize_image=True, validation=False)\n",
    "\n",
    "    print(len(bbox_annotations))\n",
    "    train_annotations_path = 'resized_data/train_annotations.json'\n",
    "\n",
    "    with open(train_annotations_path, 'w') as f:\n",
    "        json.dump(bbox_annotations, f, indent=4)\n",
    "\n",
    "    print(f\"Training images and bounding boxes saved to {train_annotations_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_training()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image_dir, annotations_path):\n",
    "    with open(annotations_path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        if annotation['has_symbol'] == 0:\n",
    "            image_path = f'{image_dir}/{annotation[\"image_path\"]}'\n",
    "            image = cv2.imread(image_path)\n",
    "            cv2.imshow('Image', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            image_path = f'{image_dir}/{annotation[\"image_path\"]}'\n",
    "            image = cv2.imread(image_path)\n",
    "            x_min = int(annotation['bbox']['x_min'])\n",
    "            y_min = int(annotation['bbox']['y_min'])\n",
    "            x_max = int(annotation['bbox']['x_max'])\n",
    "            y_max = int(annotation['bbox']['y_max'])\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "            cv2.imshow('Image', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir = 'resized_data'\n",
    "# annotations_path = 'resized_data/annotations.json'\n",
    "# visualize(image_dir, annotations_path)\n",
    "# new_dir = 'data'\n",
    "# new_annotations_path = 'data/annotations.json'\n",
    "# visualize(new_dir, new_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation(num_augmentations=20):    \n",
    "    image_path = 'original_data/back.bmp'\n",
    "    target_size = (256, 256)\n",
    "    val_annotation = generate_image(num_augmentations, 0, back_data, image_path, target_size, has_symbol=True, resize_image=True, validation=True)\n",
    "    image_path = 'original_data/back_1.bmp'\n",
    "    val_annotation += generate_image(num_augmentations, num_augmentations, back_1_data, image_path, target_size, has_symbol=True, resize_image=True, validation=True)\n",
    "    image_path = 'original_data/front.bmp'\n",
    "    val_annotation += generate_image(num_augmentations, 2 * num_augmentations, back_data, image_path, target_size, has_symbol=False, resize_image=True, validation=True)\n",
    "    image_path = 'original_data/stain_back.bmp'\n",
    "    val_annotation += generate_image(num_augmentations, 3 * num_augmentations, back_data, image_path, target_size, has_symbol=False, resize_image=True, validation=True)\n",
    "\n",
    "    print(len(val_annotation))\n",
    "    if not os.path.exists('resized_validation_data'):\n",
    "        os.makedirs('resized_validation_data')\n",
    "        \n",
    "    val_annotations_path = 'resized_validation_data/annotations.json'\n",
    "    with open(val_annotations_path, 'w') as f:\n",
    "        json.dump(val_annotation, f, indent=4)\n",
    "    print(f\"Validation images and bounding boxes saved to {val_annotations_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Validation images and bounding boxes saved to resized_validation_data/annotations.json\n"
     ]
    }
   ],
   "source": [
    "generate_validation()\n",
    "# image_dir = 'resized_validation_data'\n",
    "# annotations_path = 'resized_validation_data/annotations.json'\n",
    "# visualize(image_dir, annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image(start_index, image_path, num_images, target_size, resize=False):\n",
    "    image = cv2.imread(image_path)\n",
    "    bbox = [0, 0, 0, 0]\n",
    "    if resize:\n",
    "        if not os.path.exists('resized_test_data'):\n",
    "            os.makedirs('resized_test_data')\n",
    "    else:\n",
    "        if not os.path.exists('test_data'):\n",
    "            os.makedirs('test_data')\n",
    "    for i in range(num_images):\n",
    "        augmented_image, _ = augment_image(image.copy(), bbox.copy())\n",
    "        augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)\n",
    "        if resize:\n",
    "            augmented_image = cv2.resize(augmented_image, target_size)\n",
    "        augmented_image_path = f'test_data/image_{i+start_index}.jpg'\n",
    "        if resize:\n",
    "            augmented_image_path = f'resized_test_data/image_{i+start_index}.jpg'\n",
    "        cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original_data/stain_back.bmp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size = (256, 256)\n",
    "generate_test_image(0, 'original_data/back.bmp', 5, target_size, resize=False)\n",
    "generate_test_image(5, 'original_data/back_1.bmp', 5, target_size, resize=False)\n",
    "generate_test_image(10, 'original_data/front.bmp', 5, target_size, resize=False)\n",
    "generate_test_image(15, 'original_data/stain_back.bmp', 5, target_size, resize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'back.bmp'\n",
    "# target_size = (256, 256)\n",
    "# generate_image(image_path, target_size, resize_image=False)\n",
    "# image_dir = 'data'\n",
    "# annotations_path = 'data/annotations.json'\n",
    "# visualize(image_dir, annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_image(image_path, target_size, resize_image=False, validation=True)\n",
    "# image_dir = 'validation_data'\n",
    "# annotations_path = 'validation_data/annotations.json'\n",
    "# visualize(image_dir, annotations_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_image(image_path, target_size, resize_image=True, validation=True)\n",
    "# image_dir = 'resized_validation_data'\n",
    "# annotations_path = 'resized_validation_data/annotations.json'\n",
    "# visualize(image_dir, annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_box():\n",
    "    csv_data = {\n",
    "        \"x\": 5.075424261470773,\n",
    "        \"y\": 10.69767441860465,\n",
    "        \"width\": 19.721648558857858,\n",
    "        \"height\": 31.395348837209305,\n",
    "        \"rotation\": 0,\n",
    "        \"rectanglelabels\": [\"CCP\"],\n",
    "        \"original_width\": 1036,\n",
    "        \"original_height\": 646\n",
    "    }\n",
    "\n",
    "    # Load the original image\n",
    "    image_path = 'back.bmp'  # Update with your image path\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    x_min = int((csv_data[\"x\"] / 100) * image_width)\n",
    "    y_min = int((csv_data[\"y\"] / 100) * image_height)\n",
    "    bbox_width = int((csv_data[\"width\"] / 100) * image_width)\n",
    "    bbox_height = int((csv_data[\"height\"] / 100) * image_height)\n",
    "    x_max = x_min + bbox_width\n",
    "    y_max = y_min + bbox_height\n",
    "\n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 125, 0), 2)\n",
    "\n",
    "    # # Optionally, add label text if available\n",
    "    label = ','.join(csv_data[\"rectanglelabels\"])\n",
    "    cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "    # # Display the image with the bounding box\n",
    "    cv2.imshow('Image with Bounding Box', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    image_path = 'back.bmp'  # Update with your image path\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_img = cv2.resize(image, (256, 256))\n",
    "    cv2.imshow('Resized Image', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    original_size = (image_width, image_height)\n",
    "    target_size = (256, 256)\n",
    "    bbox = {\n",
    "        \"x_min\": x_min,\n",
    "        \"y_min\": y_min,\n",
    "        \"x_max\": x_max,\n",
    "        \"y_max\": y_max\n",
    "    }\n",
    "    adjusted_bbox = adjust_bounding_boxes([bbox], original_size, target_size)\n",
    "    adjusted_bbox = adjusted_bbox[0]\n",
    "    x_min, y_min, x_max, y_max = [int(x) for x in adjusted_bbox]\n",
    "    cv2.rectangle(resized_img, (x_min, y_min), (x_max, y_max), (0, 125, 0), 2)\n",
    "\n",
    "    # # Optionally, add label text if available\n",
    "    label = ','.join(csv_data[\"rectanglelabels\"])\n",
    "    cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "    # # Display the image with the bounding box\n",
    "    cv2.imshow('Resized Image with Bounding Box', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # color_jitter = transforms.ColorJitter(\n",
    "    #     brightness=0.2,    # Randomly change brightness\n",
    "    #     contrast=0.2,      # Randomly change contrast\n",
    "    #     saturation=0.2,    # Randomly change saturation\n",
    "    #     hue=0.1            # Randomly change hue\n",
    "    # )\n",
    "\n",
    "    # image = color_jitter(Image.fromarray(image))\n",
    "    # image = np.array(image)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    randomAffine = transforms.RandomAffine(\n",
    "        degrees=10,         # Randomly rotate between -10 and 10 degrees\n",
    "        translate=(0.1, 0.1),  # Randomly translate by 10% of the image height/width\n",
    "        scale=(0.8, 1.2),   # Randomly scale image between 0.8 and 1.2 times\n",
    "        shear=10            # Randomly shear by -10 to 10 degrees\n",
    "    )\n",
    "\n",
    "\n",
    "    image = randomAffine(Image.fromarray(image))\n",
    "    image = np.array(image)\n",
    "    cv2.imshow('Image with Bounding Box', image)\n",
    "    '''\n",
    "    # blur = transforms.GaussianBlur(kernel_size=(5,25), sigma=(0.1, 5))\n",
    "    # image = blur(Image.fromarray(image))\n",
    "    # image = np.array(image)\n",
    "    # image = image.resize((256, 256))\n",
    "    # cv2.imshow('Image with Bounding Box', image)\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "\n",
    "    #print(x_min, y_min, x_max, y_max)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_data = {\n",
    "#     \"x\": 5.075424261470773,\n",
    "#     \"y\": 10.69767441860465,\n",
    "#     \"width\": 19.721648558857858,\n",
    "#     \"height\": 31.395348837209305,\n",
    "#     \"rotation\": 0,\n",
    "#     \"rectanglelabels\": [\"CCP\"],\n",
    "#     \"original_width\": 1036,\n",
    "#     \"original_height\": 646\n",
    "# }\n",
    "\n",
    "# # Load the original image\n",
    "# image_path = 'data/back.bmp'  # Update with your image path\n",
    "# image = cv2.imread(image_path)\n",
    "# image_height, image_width, _ = image.shape\n",
    "\n",
    "# # Convert normalized coordinates to pixel coordinates\n",
    "# x_min = int((csv_data[\"x\"] / 100) * image_width)\n",
    "# y_min = int((csv_data[\"y\"] / 100) * image_height)\n",
    "# bbox_width = int((csv_data[\"width\"] / 100) * image_width)\n",
    "# bbox_height = int((csv_data[\"height\"] / 100) * image_height)\n",
    "# x_max = x_min + bbox_width\n",
    "# y_max = y_min + bbox_height\n",
    "\n",
    "# print(x_min, y_min, x_max, y_max)\n",
    "\n",
    "# image = np.flip(image, [0, 1])\n",
    "# image = np.array(image)\n",
    "\n",
    "# x_min = image_width - x_min\n",
    "# x_max = image_width - x_max\n",
    "\n",
    "# y_min = image_height - y_min\n",
    "# y_max = image_height - y_max\n",
    "\n",
    "# # Draw bounding box on the image\n",
    "# cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 125, 0), 2)\n",
    "\n",
    "# # Optionally, add label text if available\n",
    "# label = ','.join(csv_data[\"rectanglelabels\"])\n",
    "# cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "# # Display the image with the bounding box\n",
    "# cv2.imshow('Image with Bounding Box', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_data = {\n",
    "#     \"x\": 5.075424261470773,\n",
    "#     \"y\": 10.69767441860465,\n",
    "#     \"width\": 19.721648558857858,\n",
    "#     \"height\": 31.395348837209305,\n",
    "#     \"rotation\": 0,\n",
    "#     \"rectanglelabels\": [\"CCP\"],\n",
    "#     \"original_width\": 1036,\n",
    "#     \"original_height\": 646\n",
    "# }\n",
    "\n",
    "# image_path = 'back.bmp'  # Update with the actual path\n",
    "# image = cv2.imread(image_path)\n",
    "# # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for visualization\n",
    "\n",
    "# bbox = normalized_to_pixel_bbox(csv_data, csv_data[\"original_width\"], csv_data[\"original_height\"])\n",
    "\n",
    "# num_train_augmentations = 50  # Number of augmentations to generate\n",
    "# train_augmented_results = []\n",
    "\n",
    "# for i in range(num_train_augmentations):\n",
    "#     augmented_image, adjusted_bbox = augment_image(image.copy(), bbox.copy())\n",
    "#     augmented_image_np = np.array(augmented_image)\n",
    "#     train_augmented_results.append((augmented_image_np, adjusted_bbox))\n",
    "#     # print(adjusted_bbox)\n",
    "#     # Display the augmented image with the bounding box\n",
    "#     # augmented_image_path = f'augmented_image_{i}.jpg'\n",
    "#     # augmented_image_bgr = cv2.cvtColor(augmented_image_np, cv2.COLOR_RGB2BGR)\n",
    "#     # cv2.rectangle(augmented_image_bgr, (int(adjusted_bbox[0]), int(adjusted_bbox[1])), \n",
    "#     #           (int(adjusted_bbox[2]), int(adjusted_bbox[3])), (255, 0, 0), 2)\n",
    "#     # cv2.imshow('Augmented Image', augmented_image_bgr)\n",
    "#     # cv2.waitKey(0)\n",
    "#     # cv2.destroyAllWindows()\n",
    "#     # cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# train_bbox_annotations = []\n",
    "# for i, (augmented_image, adjusted_bbox) in enumerate(train_augmented_results):\n",
    "#     # Save augmented image\n",
    "#     augmented_image_path = f'data/augmented_image_{i}.jpg'\n",
    "#     image_name = f'augmented_image_{i}.jpg'\n",
    "#     cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    \n",
    "#     # Save adjusted bounding box coordinates to the annotations list\n",
    "#     bbox_data = {\n",
    "#         'image_path': image_name,\n",
    "#         'bbox': {\n",
    "#             'x_min': adjusted_bbox[0],\n",
    "#             'y_min': adjusted_bbox[1],\n",
    "#             'x_max': adjusted_bbox[2],\n",
    "#             'y_max': adjusted_bbox[3]\n",
    "#         }\n",
    "#     }\n",
    "#     train_bbox_annotations.append(bbox_data)\n",
    "\n",
    "# # Save bounding box annotations to a JSON file\n",
    "# train_annotations_path = 'data/annotations.json'\n",
    "# with open(train_annotations_path, 'w') as f:\n",
    "#     json.dump(train_bbox_annotations, f, indent=4)\n",
    "\n",
    "# print(f\"Training images and bounding boxes saved to 'data/' directory.\")\n",
    "\n",
    "\n",
    "# num_val_augmentations = 10  # Number of augmentations to generate\n",
    "# val_augmented_results = []\n",
    "\n",
    "# for i in range(num_val_augmentations):\n",
    "#     augmented_image, adjusted_bbox = augment_image(image.copy(), bbox.copy())\n",
    "#     augmented_image_np = np.array(augmented_image)\n",
    "#     val_augmented_results.append((augmented_image_np, adjusted_bbox))\n",
    "#     # print(adjusted_bbox)\n",
    "#     # Display the augmented image with the bounding box\n",
    "#     # augmented_image_path = f'augmented_image_{i}.jpg'\n",
    "#     # augmented_image_bgr = cv2.cvtColor(augmented_image_np, cv2.COLOR_RGB2BGR)\n",
    "#     # cv2.rectangle(augmented_image_bgr, (int(adjusted_bbox[0]), int(adjusted_bbox[1])), \n",
    "#     #           (int(adjusted_bbox[2]), int(adjusted_bbox[3])), (255, 0, 0), 2)\n",
    "#     # cv2.imshow('Augmented Image', augmented_image_bgr)\n",
    "#     # cv2.waitKey(0)\n",
    "#     # cv2.destroyAllWindows()\n",
    "#     # cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# val_bbox_annotations = []\n",
    "# for i, (augmented_image, adjusted_bbox) in enumerate(val_augmented_results):\n",
    "#     # Save augmented image\n",
    "#     augmented_image_path = f'val_data/augmented_image_{i}.jpg'\n",
    "#     image_name = f'augmented_image_{i}.jpg'\n",
    "#     cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    \n",
    "#     # Save adjusted bounding box coordinates to the annotations list\n",
    "#     bbox_data = {\n",
    "#         'image_path': image_name,\n",
    "#         'bbox': {\n",
    "#             'x_min': adjusted_bbox[0],\n",
    "#             'y_min': adjusted_bbox[1],\n",
    "#             'x_max': adjusted_bbox[2],\n",
    "#             'y_max': adjusted_bbox[3]\n",
    "#         }\n",
    "#     }\n",
    "#     val_bbox_annotations.append(bbox_data)\n",
    "\n",
    "# # Save bounding box annotations to a JSON file\n",
    "# val_annotations_path = 'val_data/val_annotations.json'\n",
    "# with open(val_annotations_path, 'w') as f:\n",
    "#     json.dump(val_bbox_annotations, f, indent=4)\n",
    "\n",
    "\n",
    "# print(f\"Validation images and bounding boxes saved to 'val_data/' directory.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "springv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
